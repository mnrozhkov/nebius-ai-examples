{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nebius Managed Service for MLflow Demo\n",
    "\n",
    "This demo shows you how key use cases of using the Nebius Managed Service for MLflow for AI development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "1. Launch your instance of the Managed Service for MLflow with [the MLflow quickstart](https://docs.nebius.com/mlflow/quickstart).\n",
    "2. Set up your API key to connect to Nebius AI Studio with [the AI Studio quickstart](https://docs.nebius.com/studio/inference/quickstart).\n",
    "\n",
    "> **Note:** Launching an MLflow cluster may take 30-60 minutes to be fully provisioned and ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:28:30.543262Z",
     "iopub.status.busy": "2025-03-29T19:28:30.543103Z",
     "iopub.status.idle": "2025-03-29T19:28:31.735133Z",
     "shell.execute_reply": "2025-03-29T19:28:31.734712Z",
     "shell.execute_reply.started": "2025-03-29T19:28:30.543249Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install mlflow==2.20.2 python-dotenv openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secrets and Environment Variables\n",
    "\n",
    "You will need to set the following environment variables where this notebook is running, so that the code in the following cells can connect to both Nebius Managed Service for MLflow and Nebius AI Studio. \n",
    "\n",
    "MLflow:<br>\n",
    "`MLFLOW_TRACKING_SERVER_CERT_PATH`<br>\n",
    "`MLFLOW_TRACKING_URI`<br>\n",
    "`MLFLOW_TRACKING_USERNAME`<br>\n",
    "`MLFLOW_TRACKING_PASSWORD`<br>\n",
    "\n",
    "AI Studio:<br>\n",
    "`NEBIUS_API_KEY`\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "To set the environment variables, run the following cell. You may choose to set them interactively or by loading from a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:27:47.346157Z",
     "iopub.status.busy": "2025-04-15T11:27:47.345761Z",
     "iopub.status.idle": "2025-04-15T11:27:47.373635Z",
     "shell.execute_reply": "2025-04-15T11:27:47.373389Z",
     "shell.execute_reply.started": "2025-04-15T11:27:47.346129Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add the parent directory to Python path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from env_setup import setup_env_from_file, setup_env_interactive, verify_env_setup\n",
    "\n",
    "# Option 1: Interactive setup\n",
    "# setup_env_interactive()\n",
    "\n",
    "# Option 2: Load from .env file\n",
    "setup_env_from_file('../.env')\n",
    "\n",
    "# Verify the setup\n",
    "verify_env_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check connection to MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:27:49.608183Z",
     "iopub.status.busy": "2025-04-15T11:27:49.607723Z",
     "iopub.status.idle": "2025-04-15T11:27:51.793338Z",
     "shell.execute_reply": "2025-04-15T11:27:51.792739Z",
     "shell.execute_reply.started": "2025-04-15T11:27:49.608154Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow \n",
    "\n",
    "# List experiments in MLflow\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Nebius AI Studio client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:27:54.203290Z",
     "iopub.status.busy": "2025-04-15T11:27:54.202720Z",
     "iopub.status.idle": "2025-04-15T11:27:54.633150Z",
     "shell.execute_reply": "2025-04-15T11:27:54.632866Z",
     "shell.execute_reply.started": "2025-04-15T11:27:54.203258Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "API_KEY = os.environ.get(\"NEBIUS_API_KEY\")\n",
    "\n",
    "# Instantiate the client instance\n",
    "nebius_client = openai.OpenAI(api_key=API_KEY,\n",
    "                              base_url=\"https://api.studio.nebius.ai/v1/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: MLflow Tracking Quickstart\n",
    "\n",
    "https://mlflow.org/docs/latest/getting-started/intro-quickstart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"multi_class\": \"auto\",\n",
    "    \"random_state\": 8888,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log the model and its metadata to MLflow\n",
    "\n",
    "- Initiate an MLflow run context to start a new run that we will log the model and metadata to.\n",
    "- Log model parameters and performance metrics.\n",
    "- Tag the run for easy retrieval.\n",
    "- Register the model in the MLflow Model Registry while logging (saving) the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lr.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        artifact_path=\"iris_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"tracking-quickstart\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model as a Python Function (pyfunc) and use it for inference\n",
    "\n",
    "- Loading the model using MLflow's pyfunc flavor.\n",
    "- Running Predict on new data using the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back for predictions as a generic Python Function model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions \n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: MLflow Tracing for LLM Observability\n",
    "\n",
    "Traces enhances LLM observability in your Generative AI (GenAI) applications by capturing detailed information about the execution details. \n",
    "\n",
    "https://mlflow.org/docs/latest/tracing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Tracing of LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!env | grep MLFLOW_TRACKING_SERVER_CERT_PATH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import openai\n",
    "\n",
    "tracing_experiment =mlflow.set_experiment(\"MLflow Tracing\")\n",
    "\n",
    "# Enable MLflow automatic tracing for OpenAI with one line of code!\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "\n",
    "# Time to call the LLM -- tracing is done automatically\n",
    "nebius_client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    temperature=0.95,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a chatbot.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like today?\"},\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Tracing\n",
    "\n",
    "1. Instrument a function with @mlflow.trace decorator.\n",
    "2. Instrument any block of code using mlflow.start_span context manager.\n",
    "3. Grouping or annotating traces using a tag.\n",
    "4. Disabling trace globally.\n",
    "\n",
    "https://mlflow.org/docs/latest/tracing/#manual-tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import SpanType\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MLflow tracing to trace the execution of a function\n",
    "\n",
    "@mlflow.trace(span_type=\"func\", attributes={\"key\": \"value\"})\n",
    "def add_1(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "@mlflow.trace(span_type=\"func\", attributes={\"key\": \"value\"})\n",
    "def minus_1(x):\n",
    "    return x - 1\n",
    "\n",
    "\n",
    "@mlflow.trace(name=\"Trace Test\")\n",
    "def trace_test(x):\n",
    "    step1 = add_1(x)\n",
    "    return minus_1(step1)\n",
    "\n",
    "\n",
    "trace_test(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate tracing into your LLM workflow\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "@mlflow.trace(span_type=SpanType.CHAIN)\n",
    "def run(question):\n",
    "    messages = build_messages(question)\n",
    "    # MLflow automatically generates a span for OpenAI invocation\n",
    "    response = nebius_client.chat.completions.create(\n",
    "        # model=\"gpt-4o-mini\",\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "        max_tokens=100,\n",
    "        messages=messages,\n",
    "    )\n",
    "    return parse_response(response)\n",
    "\n",
    "\n",
    "@mlflow.trace\n",
    "def build_messages(question):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chatbot.\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "\n",
    "@mlflow.trace\n",
    "def parse_response(response):\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "run(\"What is MLflow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the timestamp in milliseconds\n",
    "one_hour_ago = int(time.time() - 3600) * 1000  # 3600 seconds = 1 hour in milliseconds\n",
    "\n",
    "one_hour_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search and analyze traces\n",
    "\n",
    "mlflow.search_traces(\n",
    "    tracing_experiment.experiment_id, \n",
    "    filter_string=f\"timestamp_ms < {one_hour_ago}\",\n",
    ")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3:  Tracing LangGraph \n",
    "\n",
    "- Tracing LangGraph with MLflow https://mlflow.org/docs/latest/tracing/integrations/langgraph \n",
    "- Example: Code generation with RAG and self-correction with https://langchain-ai.github.io/langgraph/tutorials/code_assistant/langgraph_code_assistant/\n",
    "\n",
    "For this example set additional vars: \n",
    "- OPENAI_API_KEY\n",
    "- ANTHROPIC_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:06:49.327890Z",
     "iopub.status.busy": "2025-03-29T19:06:49.327241Z",
     "iopub.status.idle": "2025-03-29T19:06:51.499944Z",
     "shell.execute_reply": "2025-03-29T19:06:51.499448Z",
     "shell.execute_reply.started": "2025-03-29T19:06:49.327839Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain_openai langchain langgraph langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:07:22.389198Z",
     "iopub.status.busy": "2025-03-29T19:07:22.388532Z",
     "iopub.status.idle": "2025-03-29T19:07:27.119773Z",
     "shell.execute_reply": "2025-03-29T19:07:27.118946Z",
     "shell.execute_reply.started": "2025-03-29T19:07:22.389154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolCall\n",
    "from langchain_core.outputs import ChatGeneration, ChatResult\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Enabling tracing for LangGraph (LangChain)\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Optional: Set a tracking URI and an experiment\n",
    "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"LangGraph\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [get_weather]\n",
    "graph = create_react_agent(llm, tools)\n",
    "\n",
    "# Invoke the graph\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in tokyo?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Tracing CrewAI Agents\n",
    "\n",
    "- Example https://mlflow.org/docs/latest/tracing/integrations/crewai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:28:02.862013Z",
     "iopub.status.busy": "2025-04-15T11:28:02.861519Z",
     "iopub.status.idle": "2025-04-15T11:28:04.653321Z",
     "shell.execute_reply": "2025-04-15T11:28:04.652830Z",
     "shell.execute_reply.started": "2025-04-15T11:28:02.861983Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install crewai crewai_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:28:10.917580Z",
     "iopub.status.busy": "2025-04-15T11:28:10.917061Z",
     "iopub.status.idle": "2025-04-15T11:28:13.471936Z",
     "shell.execute_reply": "2025-04-15T11:28:13.471252Z",
     "shell.execute_reply.started": "2025-04-15T11:28:10.917547Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Turn on auto tracing by calling mlflow.crewai.autolog()\n",
    "mlflow.crewai.autolog()\n",
    "\n",
    "mlflow.set_experiment(\"CrewAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:28:16.932212Z",
     "iopub.status.busy": "2025-04-15T11:28:16.931732Z",
     "iopub.status.idle": "2025-04-15T11:28:18.651481Z",
     "shell.execute_reply": "2025-04-15T11:28:18.651229Z",
     "shell.execute_reply.started": "2025-04-15T11:28:16.932181Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Crew, Task\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "from crewai_tools import SerperDevTool, WebsiteSearchTool\n",
    "\n",
    "from textwrap import dedent\n",
    "\n",
    "content = \"Users name is John. He is 30 years old and lives in San Francisco.\"\n",
    "string_source = StringKnowledgeSource(\n",
    "    content=content, metadata={\"preference\": \"personal\"}\n",
    ")\n",
    "\n",
    "search_tool = WebsiteSearchTool()\n",
    "\n",
    "class TripAgents:\n",
    "    def city_selection_agent(self):\n",
    "        return Agent(\n",
    "            role=\"City Selection Expert\",\n",
    "            goal=\"Select the best city based on weather, season, and prices\",\n",
    "            backstory=\"An expert in analyzing travel data to pick ideal destinations\",\n",
    "            tools=[\n",
    "                search_tool,\n",
    "            ],\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "    def local_expert(self):\n",
    "        return Agent(\n",
    "            role=\"Local Expert at this city\",\n",
    "            goal=\"Provide the BEST insights about the selected city\",\n",
    "            backstory=\"\"\"A knowledgeable local guide with extensive information\n",
    "        about the city, it's attractions and customs\"\"\",\n",
    "            tools=[search_tool],\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "class TripTasks:\n",
    "    def identify_task(self, agent, origin, cities, interests, range):\n",
    "        return Task(\n",
    "            description=dedent(\n",
    "                f\"\"\"\n",
    "                Analyze and select the best city for the trip based\n",
    "                on specific criteria such as weather patterns, seasonal\n",
    "                events, and travel costs. This task involves comparing\n",
    "                multiple cities, considering factors like current weather\n",
    "                conditions, upcoming cultural or seasonal events, and\n",
    "                overall travel expenses.\n",
    "                Your final answer must be a detailed\n",
    "                report on the chosen city, and everything you found out\n",
    "                about it, including the actual flight costs, weather\n",
    "                forecast and attractions.\n",
    "\n",
    "                Traveling from: {origin}\n",
    "                City Options: {cities}\n",
    "                Trip Date: {range}\n",
    "                Traveler Interests: {interests}\n",
    "            \"\"\"\n",
    "            ),\n",
    "            agent=agent,\n",
    "            expected_output=\"Detailed report on the chosen city including flight costs, weather forecast, and attractions\",\n",
    "        )\n",
    "\n",
    "    def gather_task(self, agent, origin, interests, range):\n",
    "        return Task(\n",
    "            description=dedent(\n",
    "                f\"\"\"\n",
    "                As a local expert on this city you must compile an\n",
    "                in-depth guide for someone traveling there and wanting\n",
    "                to have THE BEST trip ever!\n",
    "                Gather information about key attractions, local customs,\n",
    "                special events, and daily activity recommendations.\n",
    "                Find the best spots to go to, the kind of place only a\n",
    "                local would know.\n",
    "                This guide should provide a thorough overview of what\n",
    "                the city has to offer, including hidden gems, cultural\n",
    "                hotspots, must-visit landmarks, weather forecasts, and\n",
    "                high level costs.\n",
    "                The final answer must be a comprehensive city guide,\n",
    "                rich in cultural insights and practical tips,\n",
    "                tailored to enhance the travel experience.\n",
    "\n",
    "                Trip Date: {range}\n",
    "                Traveling from: {origin}\n",
    "                Traveler Interests: {interests}\n",
    "            \"\"\"\n",
    "            ),\n",
    "            agent=agent,\n",
    "            expected_output=\"Comprehensive city guide including hidden gems, cultural hotspots, and practical travel tips\",\n",
    "        )\n",
    "\n",
    "\n",
    "class TripCrew:\n",
    "    def __init__(self, origin, cities, date_range, interests):\n",
    "        self.cities = cities\n",
    "        self.origin = origin\n",
    "        self.interests = interests\n",
    "        self.date_range = date_range\n",
    "\n",
    "    def run(self):\n",
    "        agents = TripAgents()\n",
    "        tasks = TripTasks()\n",
    "\n",
    "        city_selector_agent = agents.city_selection_agent()\n",
    "        local_expert_agent = agents.local_expert()\n",
    "\n",
    "        identify_task = tasks.identify_task(\n",
    "            city_selector_agent,\n",
    "            self.origin,\n",
    "            self.cities,\n",
    "            self.interests,\n",
    "            self.date_range,\n",
    "        )\n",
    "        gather_task = tasks.gather_task(\n",
    "            local_expert_agent, self.origin, self.interests, self.date_range\n",
    "        )\n",
    "\n",
    "        crew = Crew(\n",
    "            agents=[city_selector_agent, local_expert_agent],\n",
    "            tasks=[identify_task, gather_task],\n",
    "            verbose=True,\n",
    "            memory=True,\n",
    "            knowledge={\n",
    "                \"sources\": [string_source],\n",
    "                \"metadata\": {\"preference\": \"personal\"},\n",
    "                \"collection_name\":\"knowledge\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "        result = crew.kickoff()\n",
    "        return result\n",
    "\n",
    "\n",
    "trip_crew = TripCrew(\"California\", \"Tokyo\", \"Dec 12 - Dec 20\", \"sports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:28:19.419093Z",
     "iopub.status.busy": "2025-04-15T11:28:19.418389Z",
     "iopub.status.idle": "2025-04-15T11:33:07.834485Z",
     "shell.execute_reply": "2025-04-15T11:33:07.834066Z",
     "shell.execute_reply.started": "2025-04-15T11:28:19.419066Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the crew\n",
    "\n",
    "result = trip_crew.run()\n",
    "result.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:30:06.102401Z",
     "iopub.status.busy": "2025-03-29T19:30:06.101785Z",
     "iopub.status.idle": "2025-03-29T19:30:07.806796Z",
     "shell.execute_reply": "2025-03-29T19:30:07.805926Z",
     "shell.execute_reply.started": "2025-03-29T19:30:06.102348Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install crewai==0.108.0 crewai-tools duckduckgo-search langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:51:13.968003Z",
     "iopub.status.busy": "2025-03-29T19:51:13.967612Z",
     "iopub.status.idle": "2025-03-29T19:51:14.266248Z",
     "shell.execute_reply": "2025-03-29T19:51:14.265791Z",
     "shell.execute_reply.started": "2025-03-29T19:51:13.967962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from textwrap import dedent\n",
    "from crewai import Agent, Crew, Task, Process\n",
    "from crewai_tools import WebsiteSearchTool, DuckDuckGoSearchRunTool\n",
    "# You might need specific LangChain components depending on your LLM setup\n",
    "from langchain_openai import ChatOpenAI # Example for OpenAI or compatible APIs like Ollama\n",
    "\n",
    "print(\"Libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:39:42.050109Z",
     "iopub.status.busy": "2025-03-29T19:39:42.049687Z",
     "iopub.status.idle": "2025-03-29T19:39:43.009893Z",
     "shell.execute_reply": "2025-03-29T19:39:43.009388Z",
     "shell.execute_reply.started": "2025-03-29T19:39:42.050077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Turn on auto tracing by calling mlflow.crewai.autolog()\n",
    "mlflow.crewai.autolog()\n",
    "\n",
    "mlflow.set_experiment(\"CrewAI Agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:31:03.937425Z",
     "iopub.status.busy": "2025-03-29T19:31:03.936801Z",
     "iopub.status.idle": "2025-03-29T19:31:03.975347Z",
     "shell.execute_reply": "2025-03-29T19:31:03.974985Z",
     "shell.execute_reply.started": "2025-03-29T19:31:03.937390Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- VERY IMPORTANT: Configure Your LLM ---\n",
    "# Option A: Set OpenAI API Key as Environment Variable (Recommended for Simplicity)\n",
    "# Make sure your OPENAI_API_KEY environment variable is set *before* launching Jupyter/VSCode.\n",
    "# CrewAI will automatically pick it up if no specific 'llm' is passed to Agents/Crew.\n",
    "# You can uncomment the line below to set it temporarily for this session *only*\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-YOUR_API_KEY_HERE\"\n",
    "\n",
    "# Option B: Configure for a Local or Specific LLM (Example using Ollama via ChatOpenAI)\n",
    "# Ensure Ollama is running (e.g., `ollama run llama3`)\n",
    "# ollama_llm = ChatOpenAI(\n",
    "#     model=\"llama3\", # Or whichever model you are running in Ollama\n",
    "#     base_url=\"http://localhost:11434/v1\",\n",
    "#     api_key=\"NA\" # Standard practice for Ollama via langchain-openai\n",
    "# )\n",
    "# print(\"LLM Configuration (Example - Ollama): Set up.\")\n",
    "# If using Option B, you'll need to pass `llm=ollama_llm` when creating Agents below.\n",
    "\n",
    "# Check if the key is set (optional check for Option A)\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"OPENAI_API_KEY found. Agents will use the default OpenAI LLM unless specified otherwise.\")\n",
    "else:\n",
    "    print(\"WARNING: OPENAI_API_KEY environment variable not found.\")\n",
    "    print(\"Ensure an LLM is configured either via environment variables or by passing an 'llm' object to Agents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup WebsiteSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:31:30.574940Z",
     "iopub.status.busy": "2025-03-29T19:31:30.574442Z",
     "iopub.status.idle": "2025-03-29T19:31:30.725595Z",
     "shell.execute_reply": "2025-03-29T19:31:30.725353Z",
     "shell.execute_reply.started": "2025-03-29T19:31:30.574907Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Cell 3: Instantiate Tools ---\n",
    "search_tool = WebsiteSearchTool()\n",
    "# If you were using Serper:\n",
    "# from crewai_tools import SerperDevTool\n",
    "# os.environ[\"SERPER_API_KEY\"] = \"YOUR_SERPER_KEY\" # Set environment variable\n",
    "# search_tool = SerperDevTool()\n",
    "\n",
    "print(\"Tools instantiated (WebsiteSearchTool).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:31:45.338295Z",
     "iopub.status.busy": "2025-03-29T19:31:45.337742Z",
     "iopub.status.idle": "2025-03-29T19:31:45.379452Z",
     "shell.execute_reply": "2025-03-29T19:31:45.379048Z",
     "shell.execute_reply.started": "2025-03-29T19:31:45.338261Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Cell 4: Define Agent Creation Class ---\n",
    "class MLflowIntegrationAgents:\n",
    "    def trend_scout_agent(self, llm_config=None): # Pass LLM config if not relying on default\n",
    "        return Agent(\n",
    "            role=\"AI Technology Trend Scout\",\n",
    "            goal=dedent(\n",
    "                \"\"\"Identify a specific, promising new tool, library, or technique\n",
    "                within a given area of AI/ML technology.\"\"\"\n",
    "            ),\n",
    "            backstory=dedent(\n",
    "                \"\"\"An expert researcher constantly scanning the horizon\n",
    "                for emerging AI/ML technologies, publications, and popular\n",
    "                open-source projects. You prioritize novelty and potential impact.\"\"\"\n",
    "            ),\n",
    "            tools=[search_tool],\n",
    "            allow_delegation=False,\n",
    "            verbose=True,\n",
    "            llm=llm_config # Pass the specific LLM object here if needed\n",
    "        )\n",
    "\n",
    "    def technical_analyst_agent(self, llm_config=None): # Pass LLM config if not relying on default\n",
    "        return Agent(\n",
    "            role=\"AI Technical Analyst\",\n",
    "            goal=dedent(\n",
    "                \"\"\"Analyze the technical capabilities, architecture, pros, cons,\n",
    "                and primary use cases of a specific AI tool or technique.\"\"\"\n",
    "            ),\n",
    "            backstory=dedent(\n",
    "                \"\"\"A meticulous engineer who dives deep into documentation,\n",
    "                tutorials, and technical blogs to understand how technologies\n",
    "                work under the hood. You focus on practical implementation details.\"\"\"\n",
    "            ),\n",
    "            tools=[search_tool],\n",
    "            allow_delegation=False,\n",
    "            verbose=True,\n",
    "            llm=llm_config # Pass the specific LLM object here if needed\n",
    "        )\n",
    "\n",
    "    def mlflow_integration_assessor_agent(self, llm_config=None): # Pass LLM config if not relying on default\n",
    "        return Agent(\n",
    "            role=\"MLflow Integration Assessor\",\n",
    "            goal=dedent(\n",
    "                \"\"\"Assess how a given AI tool/technique could be integrated\n",
    "                into a standard MLflow workflow. Identify potential logging points,\n",
    "                artifact types, customizability needs, or existing MLflow plugins.\"\"\"\n",
    "            ),\n",
    "            backstory=dedent(\n",
    "                \"\"\"A seasoned MLOps engineer with deep expertise in MLflow.\n",
    "                You understand the ML lifecycle and how various components\n",
    "                can be tracked and managed using MLflow runs, artifacts, models,\n",
    "                and parameters. You think practically about integration points.\"\"\"\n",
    "            ),\n",
    "            tools=[search_tool], # May need search for finding MLflow plugins\n",
    "            allow_delegation=False,\n",
    "            verbose=True,\n",
    "            llm=llm_config # Pass the specific LLM object here if needed\n",
    "        )\n",
    "\n",
    "print(\"MLflowIntegrationAgents class defined.\")\n",
    "# Example instantiation check (if using Option B from Cell 2):\n",
    "# agent_creator = MLflowIntegrationAgents()\n",
    "# scout = agent_creator.trend_scout_agent(llm_config=ollama_llm)\n",
    "# print(scout) # Check agent creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:31:57.698427Z",
     "iopub.status.busy": "2025-03-29T19:31:57.697933Z",
     "iopub.status.idle": "2025-03-29T19:31:57.741666Z",
     "shell.execute_reply": "2025-03-29T19:31:57.741234Z",
     "shell.execute_reply.started": "2025-03-29T19:31:57.698394Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Cell 5: Define Task Creation Class ---\n",
    "class MLflowIntegrationTasks:\n",
    "    # Task 1: No context needed as it's the first step\n",
    "    def scout_task(self, agent, area_of_interest):\n",
    "        return Task(\n",
    "            description=dedent(\n",
    "                f\"\"\"\n",
    "                Identify one specific, noteworthy, and relatively new open-source tool,\n",
    "                library, or technique related to '{area_of_interest}'.\n",
    "                Provide its name and a brief (1-2 sentence) description of what it does.\n",
    "                Focus on things gaining traction or offering novel capabilities.\n",
    "                Avoid general concepts; find a concrete example.\n",
    "\n",
    "                Example Areas: Vector Databases, LLM Serving Frameworks,\n",
    "                               Data Versioning for ML, Explainable AI Libraries.\n",
    "\n",
    "                Your final output MUST be the name of the tool/technique and the brief description ONLY.\n",
    "            \"\"\"\n",
    "            ),\n",
    "            agent=agent,\n",
    "            expected_output=\"The name of a specific tool/library/technique and a 1-2 sentence description.\",\n",
    "            # cache=True # Optional: Cache the output of this task\n",
    "        )\n",
    "\n",
    "    # Task 2: Depends on the output of scout_task\n",
    "    def analyze_task(self, agent, area_of_interest, context_task): # Added context_task parameter\n",
    "        return Task(\n",
    "            description=dedent(\n",
    "                f\"\"\"\n",
    "                Based on the tool/technique identified in the previous step for the area '{area_of_interest}',\n",
    "                perform a technical analysis. Research its core features, how it works\n",
    "                (high-level architecture if possible), main benefits, and potential drawbacks or limitations.\n",
    "                Use web search to find its documentation, tutorials, or technical articles.\n",
    "\n",
    "                Your final output must be a bulleted list summarizing:\n",
    "                - Core Features\n",
    "                - How it Works (Briefly)\n",
    "                - Key Benefits\n",
    "                - Potential Drawbacks/Limitations\n",
    "            \"\"\"\n",
    "            ),\n",
    "            agent=agent,\n",
    "            expected_output=\"Bulleted list summarizing features, workings, benefits, and drawbacks.\",\n",
    "            context=[context_task] # Explicitly state dependency on the previous task\n",
    "            # cache=True # Optional: Cache the output of this task\n",
    "        )\n",
    "\n",
    "    # Task 3: Depends on the output of analyze_task\n",
    "    def assess_mlflow_integration_task(self, agent, context_task): # Added context_task parameter\n",
    "        return Task(\n",
    "            description=dedent(\n",
    "                f\"\"\"\n",
    "                Considering the identified tool/technique and its technical analysis from the previous steps:\n",
    "                Assess how this tool/technique could be integrated with or tracked by MLflow.\n",
    "                Think about the typical ML lifecycle (data prep, training, evaluation, deployment, monitoring).\n",
    "                Specifically suggest:\n",
    "                1.  What parameters related to this tool could be logged to MLflow?\n",
    "                2.  What metrics could be tracked?\n",
    "                3.  What kind of artifacts could be logged (e.g., config files, model files specific to the tool, evaluation plots)?\n",
    "                4.  Are there any known MLflow plugins or standard integration patterns? (Perform a quick search if unsure).\n",
    "                5.  What are the key challenges or considerations for integration?\n",
    "\n",
    "                Your final output must be a report addressing these 5 points clearly.\n",
    "                Focus solely on the MLflow integration aspect.\n",
    "            \"\"\"\n",
    "            ),\n",
    "            agent=agent,\n",
    "            expected_output=\"A report detailing potential MLflow integration points (params, metrics, artifacts), known integrations, and challenges.\",\n",
    "            context=[context_task] # Explicitly state dependency on the previous task\n",
    "        )\n",
    "\n",
    "print(\"MLflowIntegrationTasks class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T19:42:06.271800Z",
     "iopub.status.busy": "2025-03-29T19:42:06.271207Z",
     "iopub.status.idle": "2025-03-29T19:44:07.718761Z",
     "shell.execute_reply": "2025-03-29T19:44:07.718111Z",
     "shell.execute_reply.started": "2025-03-29T19:42:06.271761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Cell 6: Define the Crew Class (with MLflow additions) ---\n",
    "import mlflow\n",
    "import time\n",
    "import json # Needed for logging dicts\n",
    "from crewai import __version__ as crewai_version # Get CrewAI version\n",
    "\n",
    "class MLflowIntegrationCrew:\n",
    "    def __init__(self, area_of_interest):\n",
    "        self.area_of_interest = area_of_interest\n",
    "        # Determine LLM config (as before)\n",
    "        self.llm_config = None # Default to env vars\n",
    "\n",
    "        # Store agent/task definitions for logging\n",
    "        self.agents_config = {}\n",
    "        self.tasks_config = {}\n",
    "\n",
    "    def _log_configs(self):\n",
    "        \"\"\"Logs agent and task configurations as artifacts.\"\"\"\n",
    "        print(\"Logging configurations to MLflow...\")\n",
    "        # Log agent configs\n",
    "        for name, agent_obj in self.agents_config.items():\n",
    "            # Convert Agent object to a dictionary (might need refinement based on Agent structure)\n",
    "            # Simple example: extracting key attributes\n",
    "            agent_dict = {\n",
    "                \"role\": agent_obj.role,\n",
    "                \"goal\": agent_obj.goal,\n",
    "                \"backstory\": agent_obj.backstory,\n",
    "                \"tools\": [tool.name for tool in agent_obj.tools] if agent_obj.tools else [],\n",
    "                \"llm\": str(agent_obj.llm) if agent_obj.llm else \"Default\",\n",
    "                \"verbose\": agent_obj.verbose,\n",
    "                \"allow_delegation\": agent_obj.allow_delegation\n",
    "            }\n",
    "            mlflow.log_dict(agent_dict, f\"agent_configs/{name}_config.json\")\n",
    "\n",
    "        # Log task configs\n",
    "        for name, task_obj in self.tasks_config.items():\n",
    "            task_dict = {\n",
    "                \"description\": task_obj.description,\n",
    "                \"expected_output\": task_obj.expected_output,\n",
    "                \"agent\": task_obj.agent.role if task_obj.agent else \"N/A\", # Log agent role\n",
    "                 # Context might be complex to serialize, log its task name/description if possible\n",
    "                \"context_task_descriptions\": [ctx.description for ctx in task_obj.context] if task_obj.context else [],\n",
    "            }\n",
    "            mlflow.log_dict(task_dict, f\"task_configs/{name}_config.json\")\n",
    "\n",
    "    def run(self):\n",
    "        start_time = time.time()\n",
    "        final_result = None\n",
    "        status = \"FAILURE\" # Default status\n",
    "\n",
    "        # --- MLflow Run Start ---\n",
    "        # You might want to set experiment name outside the class or pass it in\n",
    "        # mlflow.set_experiment(\"CrewAI MLflow Demo\")\n",
    "        with mlflow.start_run(run_name=f\"CrewAI_Scout_{self.area_of_interest[:30]}\") as run:\n",
    "            print(f\"MLflow Run started: {run.info.run_id}\")\n",
    "\n",
    "            # 1. Log Parameters & Tags\n",
    "            print(\"Logging parameters and tags...\")\n",
    "            mlflow.log_param(\"area_of_interest\", self.area_of_interest)\n",
    "            mlflow.log_param(\"crew_process\", \"sequential\") # Assuming sequential\n",
    "            mlflow.log_param(\"crewai_version\", crewai_version)\n",
    "            mlflow.set_tag(\"crew_input_area\", self.area_of_interest)\n",
    "            mlflow.set_tag(\"crewai_version\", crewai_version)\n",
    "            # Add LLM info if available/consistent\n",
    "            # llm_model_name = self.llm_config.model_name if self.llm_config else \"Default\"\n",
    "            # mlflow.log_param(\"llm_model\", llm_model_name)\n",
    "            # mlflow.set_tag(\"llm_model\", llm_model_name)\n",
    "\n",
    "            # Instantiate agents & tasks, store their configs\n",
    "            agent_creator = MLflowIntegrationAgents()\n",
    "            task_creator = MLflowIntegrationTasks()\n",
    "\n",
    "            self.agents_config = {\n",
    "                \"trend_scout\": agent_creator.trend_scout_agent(self.llm_config),\n",
    "                \"tech_analyst\": agent_creator.technical_analyst_agent(self.llm_config),\n",
    "                \"mlflow_assessor\": agent_creator.mlflow_integration_assessor_agent(self.llm_config),\n",
    "            }\n",
    "            # Assign agents to local variables for clarity if needed\n",
    "            trend_scout = self.agents_config[\"trend_scout\"]\n",
    "            tech_analyst = self.agents_config[\"tech_analyst\"]\n",
    "            mlflow_assessor = self.agents_config[\"mlflow_assessor\"]\n",
    "\n",
    "            # Define tasks sequentially and store configs\n",
    "            scout_task = task_creator.scout_task(trend_scout, self.area_of_interest)\n",
    "            analyze_task = task_creator.analyze_task(tech_analyst, self.area_of_interest, context_task=scout_task)\n",
    "            assess_task = task_creator.assess_mlflow_integration_task(mlflow_assessor, context_task=analyze_task)\n",
    "\n",
    "            self.tasks_config = {\n",
    "                \"scout_task\": scout_task,\n",
    "                \"analyze_task\": analyze_task,\n",
    "                \"assess_task\": assess_task\n",
    "            }\n",
    "\n",
    "            # Log Agent/Task Counts\n",
    "            mlflow.log_metric(\"agent_count\", len(self.agents_config))\n",
    "            mlflow.log_metric(\"task_count\", len(self.tasks_config))\n",
    "            mlflow.set_tag(\"crew_agents\", \"|\".join(self.agents_config.keys()))\n",
    "\n",
    "            # Log full configs as artifacts\n",
    "            self._log_configs()\n",
    "\n",
    "            # Form the crew\n",
    "            crew = Crew(\n",
    "                agents=list(self.agents_config.values()),\n",
    "                tasks=list(self.tasks_config.values()),\n",
    "                process=Process.sequential,\n",
    "                verbose=True, # Keep verbose True to capture logs if needed\n",
    "                # llm=self.llm_config # Optional crew-level LLM\n",
    "            )\n",
    "\n",
    "            # 2. Execute the Crew & Capture Output/Logs\n",
    "            print(\"\\nAttempting to kickoff the crew...\")\n",
    "            try:\n",
    "                # --- Capture verbose output ---\n",
    "                # This part can be tricky in standard notebooks.\n",
    "                # Option A: Use a context manager if available (e.g., from libraries like `io`, `contextlib`)\n",
    "                # Option B: Run as script and redirect stdout/stderr (easier)\n",
    "                # Option C: Rely on parsing the 'final_result' if it contains verbose output (less common now)\n",
    "\n",
    "                # Simple approach: run and hope final_result is useful, log separately if needed\n",
    "                final_result = crew.kickoff()\n",
    "                status = \"SUCCESS\"\n",
    "                print(\"Crew kickoff successful.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                status = \"FAILURE\"\n",
    "                final_result = f\"Error Type: {type(e).__name__}\\nError Details: {e}\\n\\nTraceback:\\n{traceback.format_exc()}\"\n",
    "                print(f\"\\n--- Crew Execution Failed ---\")\n",
    "                print(final_result)\n",
    "                # Optionally re-raise the exception if you want the notebook cell to fail\n",
    "                # raise e\n",
    "            finally:\n",
    "                # 3. Log Results & Metrics\n",
    "                end_time = time.time()\n",
    "                execution_time = end_time - start_time\n",
    "                print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "                print(\"Logging results and metrics...\")\n",
    "\n",
    "                mlflow.log_metric(\"execution_time_seconds\", execution_time)\n",
    "                mlflow.set_tag(\"crew_status\", status)\n",
    "                mlflow.log_metric(\"success\", 1 if status == \"SUCCESS\" else 0)\n",
    "\n",
    "                # Log final output as text artifact\n",
    "                if isinstance(final_result, str):\n",
    "                    mlflow.log_text(final_result, \"final_output.txt\")\n",
    "                else:\n",
    "                     # Try logging as JSON if it's dict-like, else convert to string\n",
    "                    try:\n",
    "                        mlflow.log_dict(dict(final_result), \"final_output.json\") # Requires result implement items()\n",
    "                    except:\n",
    "                         mlflow.log_text(str(final_result), \"final_output.txt\")\n",
    "\n",
    "                # --- How to log intermediate steps/verbose log? ---\n",
    "                # If running as a script redirecting output:\n",
    "                # with open(\"execution_log.txt\", \"r\") as f:\n",
    "                #    mlflow.log_artifact(\"execution_log.txt\")\n",
    "\n",
    "                # Placeholder - Add logic here if you capture verbose logs some other way\n",
    "                print(\"Placeholder: Add logic to capture and log verbose execution output if needed.\")\n",
    "\n",
    "                print(f\"MLflow Run completed: {run.info.run_id}\")\n",
    "\n",
    "        return final_result, status # Return status along with result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run \n",
    "\n",
    "#### Suggested area Topics:\n",
    "\n",
    "LLM Focused:\n",
    "\n",
    "- \"Tools for fine-tuning open-source LLMs\" (e.g., Axolotl, Unsloth, libraries for PEFT)\n",
    "- \"Frameworks for evaluating LLM outputs\" (e.g., Ragas, DeepEval, TruLens)\n",
    "- \"LLM Observability platforms\" (e.g., LangSmith, Helicone, Weights & Biases integrations)\n",
    "- \"Prompt engineering & management toolkits\" (e.g., Promptfoo, LangChain/LlamaIndex prompt templates, specialized libraries)\n",
    "- \"Quantization libraries for LLMs\" (e.g., AutoGPTQ, bitsandbytes wrappers, specific toolkits)\n",
    "\n",
    "RAG Focused:\n",
    "- \"Scalable Vector Databases for RAG\" (e.g., Qdrant, Weaviate, Milvus alternatives or new entrants)\n",
    "- \"Frameworks implementing advanced RAG techniques\" (e.g., Self-RAG, Corrective RAG, ReAct pattern libraries)\n",
    "- \"Evaluation frameworks specifically for RAG pipelines\" (e.g., Ragas, TruLens focus on RAG metrics)\n",
    "\n",
    "Agentic AI Focused:\n",
    "- \"Alternative AI Agent frameworks to LangChain/CrewAI\" (e.g., Autogen, BabyAGI variants, new research frameworks)\n",
    "- \"Tools for creating and managing agent actions/tools\" (Libraries simplifying tool definition and secure execution)\n",
    "- \"Frameworks for multi-agent system orchestration\" (e.g., Autogen, specialized simulation environments)\n",
    "\n",
    "General GenAI Dev Tools:\n",
    "- \"Orchestration tools for complex LLM/RAG pipelines\" (e.g., Kestra, Dagster integrations for LLMs)\n",
    "- \"Synthetic data generation tools using LLMs\" (Libraries focused on generating structured/unstructured data)\n",
    "\n",
    "Tips for Choosing:\n",
    "- Specificity: More specific topics often yield better results than very broad ones.\n",
    "- Recency: Focus on areas where new tools are actively emerging.\n",
    "- MLflow Relevance: While all can be tracked, areas like \"Observability,\" \"Evaluation,\" \"Fine-tuning,\" and \"Orchestration\" have very direct conceptual links to MLflow's core purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T20:05:30.237483Z",
     "iopub.status.busy": "2025-03-29T20:05:30.237272Z",
     "iopub.status.idle": "2025-03-29T20:07:36.973405Z",
     "shell.execute_reply": "2025-03-29T20:07:36.972485Z",
     "shell.execute_reply.started": "2025-03-29T20:05:30.237464Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Cell 8: Run the Crew and Display Results (Modified) ---\n",
    "import traceback # Needed for logging exception tracebacks\n",
    "\n",
    "print(\"Running the crew with MLflow Tracing...\")\n",
    "area = \"Evaluation frameworks specifically for RAG pipelines\"\n",
    "integration_crew = MLflowIntegrationCrew(area_of_interest=area)\n",
    "\n",
    "# Run and capture status\n",
    "final_result, run_status = integration_crew.run()\n",
    "\n",
    "print(\"\\n\\n########################\")\n",
    "print(f\"## Crew Run Status: {run_status} ##\")\n",
    "print(\"########################\\n\")\n",
    "\n",
    "print(\"Final Output (also logged to MLflow):\")\n",
    "print(final_result)\n",
    "\n",
    "# You can now go to the MLflow UI (usually `mlflow ui` in terminal) to see the run details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import io\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class AIOpsResearchCrew:\n",
    "    def __init__(self, task, ai_stack):\n",
    "        \"\"\"\n",
    "        Initialize the crew with the task description and existing AI stack.\n",
    "        \n",
    "        Args:\n",
    "            task (str): Description of the task requiring AI tools\n",
    "            ai_stack (str): Comma-separated list of existing tools/frameworks used\n",
    "        \"\"\"\n",
    "        self.task = task\n",
    "        self.ai_stack = ai_stack\n",
    "        self.run_id = None\n",
    "        self.execution_log = io.StringIO()\n",
    "        self.crew = None\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Execute the research, analysis, and reporting process with MLflow tracking.\"\"\"\n",
    "        \n",
    "        # --- UPDATE: Start MLflow run ---\n",
    "        with mlflow.start_run(run_name=f\"Tool_Research_{int(time.time())}\") as mlflow_run:\n",
    "            self.run_id = mlflow_run.info.run_id\n",
    "            \n",
    "            # --- UPDATE: Log parameters ---\n",
    "            mlflow.log_param(\"task\", self.task)\n",
    "            mlflow.log_param(\"ai_stack\", self.ai_stack)\n",
    "            \n",
    "            # --- UPDATE: Capture console output ---\n",
    "            with contextlib.redirect_stdout(self.execution_log), contextlib.redirect_stderr(self.execution_log):\n",
    "                try:\n",
    "                    # Initialize agents\n",
    "                    logger.info(\"Initializing agents...\")\n",
    "                    agents = AIOpsResearchAgents()\n",
    "                    researcher = agents.researcher_agent()\n",
    "                    analyst = agents.analyst_agent()\n",
    "                    \n",
    "                    # Initialize tasks\n",
    "                    logger.info(\"Setting up tasks...\")\n",
    "                    tasks = AIOpsResearchTasks()\n",
    "                    search_task = tasks.search_tools_task(researcher, self.task, self.ai_stack)\n",
    "                    \n",
    "                    # Create the crew\n",
    "                    logger.info(\"Creating crew...\")\n",
    "                    crew = Crew(\n",
    "                        agents=[researcher, analyst],\n",
    "                        tasks=[search_task],\n",
    "                        verbose=True,\n",
    "                        process=Process.sequential,\n",
    "                        memory=True\n",
    "                    )\n",
    "                    self.crew = crew\n",
    "                    \n",
    "                    # Add dependent tasks\n",
    "                    analyze_task = tasks.analyze_tools_task(analyst, self.task, self.ai_stack)\n",
    "                    crew.tasks.append(analyze_task)\n",
    "                    \n",
    "                    report_task = tasks.create_report_task(analyst, self.task, self.ai_stack)\n",
    "                    crew.tasks.append(report_task)\n",
    "                    \n",
    "                    # Start the crew\n",
    "                    logger.info(\"Starting crew execution...\")\n",
    "                    result = crew.kickoff()\n",
    "  \n",
    "                    # --- UPDATE: Log metrics ---\n",
    "                    logger.info(\"Starting log metrics...\")\n",
    "                    if hasattr(crew, \"usage_metrics\") and crew.usage_metrics:\n",
    "                        mlflow.log_metrics(json.loads(crew.usage_metrics.json()))\n",
    "\n",
    "                    \n",
    "                    # --- UPDATE: Log task artifacts if they exist ---\n",
    "                    self._log_artifacts()\n",
    "\n",
    "                    # --- UPDATE: Set success tag ---\n",
    "                    if os.path.exists(\"output/tool_recommendation_report.md\"):\n",
    "                        mlflow.set_tag(\"status\", \"SUCCESS\")\n",
    "                    else:\n",
    "                        mlflow.set_tag(\"status\", \"FAILED\")\n",
    "                    \n",
    "                    return result\n",
    "                \n",
    "                # --- UPDATE: Log execution status and logs \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error during crew execution: {str(e)}\", exc_info=True)\n",
    "                    mlflow.set_tag(\"status\", \"FAILED\")\n",
    "                    mlflow.log_metric(\"success\", 0)\n",
    "                    raise e\n",
    "                \n",
    "                finally:\n",
    "                    # Log execution trace\n",
    "                    logger.info(\"Logging execution trace...\")\n",
    "                    execution_log = self.execution_log.getvalue()\n",
    "                    mlflow.log_text(execution_log, \"execution_log.txt\")\n",
    "\n",
    "    def _log_artifacts(self):\n",
    "        \"\"\"Log task output artifacts to MLflow.\"\"\"\n",
    "        artifact_files = [\n",
    "            (\"output/tool_candidates.json\", \"Task 1: Tool Discovery\"),\n",
    "        ]\n",
    "        \n",
    "        for file_path, description in artifact_files:\n",
    "            if os.path.exists(file_path):\n",
    "                logger.info(f\"Logging artifact: {file_path}\")\n",
    "                mlflow.log_artifact(file_path)\n",
    "                \n",
    "                # For JSON files, also log as parameters for easier viewing\n",
    "                if file_path.endswith('.json'):\n",
    "                    try:\n",
    "                        with open(file_path, 'r') as f:\n",
    "                            data = json.load(f)\n",
    "                            \n",
    "                        # Log tool names as parameters\n",
    "                        tool_names = [tool.get('name', f\"Tool {i+1}\") for i, tool in enumerate(data)]\n",
    "                        mlflow.log_param(\"discovered_tools\", \", \".join(tool_names))\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Error logging JSON data from {file_path}: {str(e)}\")\n",
    "            else:\n",
    "                logger.warning(f\"Artifact file not found: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-nebius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
