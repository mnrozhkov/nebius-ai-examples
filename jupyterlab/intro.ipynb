{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fa1090-b8fc-438d-ba08-075d03760c9f",
   "metadata": {},
   "source": [
    "![title](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63ebbc-0239-4a03-b3ec-f600102daaf2",
   "metadata": {},
   "source": [
    "# Congratulations! ðŸŽ‰ \n",
    "\n",
    "You have successfully installed JupyterLab in [Nebius AI](https://nebius.ai)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c381d-3150-4613-b38c-d4bd5dce41cc",
   "metadata": {},
   "source": [
    "Let's start with some useful tips:\n",
    "\n",
    "* [How to check that GPUs are available](#How-to-check-that-GPUs-are-available)\n",
    "\n",
    "* [How to check PyTorch and CUDA](#How-to-check-PyTorch-and-CUDA)\n",
    "\n",
    "* [How to download example notebooks from Hugging Face](#How-to-download-example-notebooks-from-Hugging-Face)\n",
    "\n",
    "* [Useful links](#Useful-links)\n",
    "\n",
    "In some of these sections, you will need to run cells: select a cell and press **Ctrl** + **Enter**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf134c-c897-4493-8ad4-1b7a5a466311",
   "metadata": {},
   "source": [
    "## How to check that GPUs are available\n",
    "\n",
    "Run the next cell to check that GPUs are found and function correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0dccee3-c538-46ad-a10b-3d65d41d96d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 20 13:19:00 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:8D:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             68W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi || echo \"No GPUs available\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9f0e2-b3af-45f2-b6f6-90f54b965082",
   "metadata": {},
   "source": [
    "## How to check PyTorch and CUDA\n",
    "\n",
    "Run the next cell to check that PyTorch is installed and ready to use CUDA on GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff067f5-937f-41a5-9c37-1944d95ae315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA current device: 0\n",
      "CUDA current device name: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    cuda_current_device = torch.cuda.current_device()\n",
    "    print(f\"CUDA current device: {cuda_current_device}\")\n",
    "    print(f\"CUDA current device name: {torch.cuda.get_device_name(cuda_current_device)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9709cfb-077a-4fca-98d4-a04872045d30",
   "metadata": {},
   "source": [
    "## How to download example notebooks from Hugging Face\n",
    "\n",
    "Run the next cell and check the downloaded files in the file browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b34fe-cd1a-4203-bc76-05782cf68a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/notebooks.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d73b93-2b07-470c-ab34-45df3728ca4e",
   "metadata": {},
   "source": [
    "## Useful links\n",
    "\n",
    "* [JupyterLab documentation](https://jupyterlab.readthedocs.io/en/latest/): working with notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-default]",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
